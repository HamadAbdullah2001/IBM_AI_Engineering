{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad09e890",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e11168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamad\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
    "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8530d02",
   "metadata": {},
   "source": [
    "# Build the neural network\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c450fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units = 10, activation = 'relu'))\n",
    "    model.add(Dense(units = 1, activation = 'linear'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb096a1a",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc981fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"concrete_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a9716",
   "metadata": {},
   "source": [
    "# Split the data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f09507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n",
      "(1030,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Strength', axis = 1)\n",
    "y = df['Strength']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42601c73",
   "metadata": {},
   "source": [
    "# Normalize the data\n",
    "\n",
    "- Use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29988b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "      <td>1.030000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.432224e-15</td>\n",
       "      <td>-8.513686e-16</td>\n",
       "      <td>3.837815e-16</td>\n",
       "      <td>1.846743e-15</td>\n",
       "      <td>-9.641155e-16</td>\n",
       "      <td>6.818710e-15</td>\n",
       "      <td>1.232571e-14</td>\n",
       "      <td>3.640022e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.714421e+00</td>\n",
       "      <td>-8.564718e-01</td>\n",
       "      <td>-8.467326e-01</td>\n",
       "      <td>-2.798851e+00</td>\n",
       "      <td>-1.038638e+00</td>\n",
       "      <td>-2.211064e+00</td>\n",
       "      <td>-2.239829e+00</td>\n",
       "      <td>-7.070160e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.496407e-01</td>\n",
       "      <td>-8.564718e-01</td>\n",
       "      <td>-8.467326e-01</td>\n",
       "      <td>-7.805147e-01</td>\n",
       "      <td>-1.038638e+00</td>\n",
       "      <td>-5.262618e-01</td>\n",
       "      <td>-5.317114e-01</td>\n",
       "      <td>-6.120340e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-7.911350e-02</td>\n",
       "      <td>-6.014861e-01</td>\n",
       "      <td>-8.467326e-01</td>\n",
       "      <td>1.607513e-01</td>\n",
       "      <td>3.269920e-02</td>\n",
       "      <td>-6.326279e-02</td>\n",
       "      <td>7.383152e-02</td>\n",
       "      <td>-2.795973e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.586406e-01</td>\n",
       "      <td>8.003558e-01</td>\n",
       "      <td>1.001791e+00</td>\n",
       "      <td>4.885554e-01</td>\n",
       "      <td>6.688058e-01</td>\n",
       "      <td>7.264077e-01</td>\n",
       "      <td>6.288606e-01</td>\n",
       "      <td>1.636517e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.476712e+00</td>\n",
       "      <td>3.309068e+00</td>\n",
       "      <td>2.279976e+00</td>\n",
       "      <td>3.064159e+00</td>\n",
       "      <td>4.351528e+00</td>\n",
       "      <td>2.213149e+00</td>\n",
       "      <td>2.731735e+00</td>\n",
       "      <td>5.055221e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cement  Blast Furnace Slag       Fly Ash         Water  \\\n",
       "count  1.030000e+03        1.030000e+03  1.030000e+03  1.030000e+03   \n",
       "mean   2.432224e-15       -8.513686e-16  3.837815e-16  1.846743e-15   \n",
       "std    1.000000e+00        1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.714421e+00       -8.564718e-01 -8.467326e-01 -2.798851e+00   \n",
       "25%   -8.496407e-01       -8.564718e-01 -8.467326e-01 -7.805147e-01   \n",
       "50%   -7.911350e-02       -6.014861e-01 -8.467326e-01  1.607513e-01   \n",
       "75%    6.586406e-01        8.003558e-01  1.001791e+00  4.885554e-01   \n",
       "max    2.476712e+00        3.309068e+00  2.279976e+00  3.064159e+00   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate           Age  \n",
       "count      1.030000e+03      1.030000e+03    1.030000e+03  1.030000e+03  \n",
       "mean      -9.641155e-16      6.818710e-15    1.232571e-14  3.640022e-16  \n",
       "std        1.000000e+00      1.000000e+00    1.000000e+00  1.000000e+00  \n",
       "min       -1.038638e+00     -2.211064e+00   -2.239829e+00 -7.070160e-01  \n",
       "25%       -1.038638e+00     -5.262618e-01   -5.317114e-01 -6.120340e-01  \n",
       "50%        3.269920e-02     -6.326279e-02    7.383152e-02 -2.795973e-01  \n",
       "75%        6.688058e-01      7.264077e-01    6.288606e-01  1.636517e-01  \n",
       "max        4.351528e+00      2.213149e+00    2.731735e+00  5.055221e+00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = (X - X.mean()) / X.std()\n",
    "X_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d350e05",
   "metadata": {},
   "source": [
    "# 1. Split the data into training and testing\n",
    "\n",
    "- Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_splithelper function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de03037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y):\n",
    "    return train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_split(X_norm, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be820f3f",
   "metadata": {},
   "source": [
    "# 2. Train the model\n",
    "\n",
    "- Train the model on the training data using 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9251df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1602.7351\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1587.2812\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1572.1476\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 999us/step - loss: 1557.0566\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1541.6428\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 970us/step - loss: 1525.8602\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1509.5376\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1492.3927\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1474.4287\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1455.6488\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1435.5514\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1414.5645\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1392.5779\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1369.4180\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1345.3138\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1319.8054\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1294.5841\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1266.6315\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1239.1542\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1210.6428\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1181.6112\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1151.9498\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1122.2618\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1091.7280\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1061.8345\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1031.5908\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1002.0156\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 972.0017\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 943.0026\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 914.1423\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 885.9668\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 858.1877\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 831.3268\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 804.6562\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 778.6728\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 753.7012\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 729.2632\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 705.4635\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 682.2250\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 660.0895\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 638.1022\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 617.1896\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 596.8013\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 577.2850\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 558.1102\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 539.6904\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 521.9155\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 504.4824\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 487.2591\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 471.1895\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 454.9380\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 439.8662\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 424.8072\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 410.3266\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 396.6948\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 383.1737\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 370.2436\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 357.9801\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 345.7740\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 334.5744\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 323.4081\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 313.1476\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 303.1568\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 293.5948\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 284.8371\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 276.3127\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 268.3200\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 260.7844\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 253.7831\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 247.0872\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 241.0285\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 235.0222\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 229.5155\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 224.4256\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 219.6521\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 215.1791\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 210.8575\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 207.1057\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 710us/step - loss: 203.4339\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 200.0124\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 196.7977\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 193.6820\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 190.9049\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 826us/step - loss: 188.3304\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 185.6736\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 183.1173\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 180.8626\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 178.7040\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 176.5576\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 174.7061\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 172.8493\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 171.0793\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 169.4791\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 167.8807\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 166.4433\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 164.9509\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 163.5977\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 162.3140\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 160.9727\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 159.7188\n"
     ]
    }
   ],
   "source": [
    "def model_training(X_train, y_train, verbose = 0):\n",
    "    model = NN()\n",
    "    model.fit(X_train, y_train, epochs = 100, verbose = verbose)\n",
    "    return model\n",
    "\n",
    "model = model_training(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11433bd6",
   "metadata": {},
   "source": [
    "# 3. Evaluate the model\n",
    "\n",
    "- Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24781175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "MSE : 141.48445322706954\n"
     ]
    }
   ],
   "source": [
    "def prediction(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MSE : {prediction(model, X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f21c8d",
   "metadata": {},
   "source": [
    "# 4. Repeat steps 1 to 3\n",
    "\n",
    "- Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049957fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 2 :-\n",
      "10/10 [==============================] - 0s 117us/step\n",
      "Model 3 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 4 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 5 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 6 :-\n",
      "10/10 [==============================] - 0s 740us/step\n",
      "Model 7 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 8 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 9 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 10 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 11 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 12 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 13 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 14 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 15 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 16 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 17 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 18 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 19 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 20 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 21 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 22 :-\n",
      "10/10 [==============================] - 0s 783us/step\n",
      "Model 23 :-\n",
      "10/10 [==============================] - 0s 917us/step\n",
      "Model 24 :-\n",
      "10/10 [==============================] - 0s 994us/step\n",
      "Model 25 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 26 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 27 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 28 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 29 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 30 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 31 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 32 :-\n",
      "10/10 [==============================] - 0s 779us/step\n",
      "Model 33 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 34 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 35 :-\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "Model 36 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 37 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 38 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 39 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 40 :-\n",
      "10/10 [==============================] - 0s 867us/step\n",
      "Model 41 :-\n",
      "10/10 [==============================] - 0s 972us/step\n",
      "Model 42 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 43 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 44 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 45 :-\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Model 46 :-\n",
      "10/10 [==============================] - 0s 862us/step\n",
      "Model 47 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 48 :-\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Model 49 :-\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Model 50 :-\n",
      "10/10 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "MSE_lst = []\n",
    "\n",
    "for i in range (50):\n",
    "    X_train, X_test, y_train, y_test = data_split(X_norm, y)\n",
    "    print(f'Model {i+1} :-')\n",
    "    model = model_training(X_train, y_train)\n",
    "    mse = prediction(model, X_test, y_test)\n",
    "    MSE_lst.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37716bc0",
   "metadata": {},
   "source": [
    "# Report for MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d631f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.238384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.043301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.170561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138.437919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157.632227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>166.032033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>196.991326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>147.480725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>161.126104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>149.923031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>203.386159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>224.935889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>157.065308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>165.973903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>157.710856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>157.299062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>147.717469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>171.238387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>176.103591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>171.535644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>167.615294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>168.099517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>155.913472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>172.609828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>155.327855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>175.150821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>144.647325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>163.491008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>178.125317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>165.299600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>162.492451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>213.452152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>171.631053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>162.225932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>184.554153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>153.097067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>164.060239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>171.030646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>143.395749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>234.583931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>157.855754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>179.916756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>212.003756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>189.189779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>178.713933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>177.937860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>157.977549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>146.242376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>178.384513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>186.465019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE\n",
       "1   158.238384\n",
       "2   154.043301\n",
       "3   196.170561\n",
       "4   138.437919\n",
       "5   157.632227\n",
       "6   166.032033\n",
       "7   196.991326\n",
       "8   147.480725\n",
       "9   161.126104\n",
       "10  149.923031\n",
       "11  203.386159\n",
       "12  224.935889\n",
       "13  157.065308\n",
       "14  165.973903\n",
       "15  157.710856\n",
       "16  157.299062\n",
       "17  147.717469\n",
       "18  171.238387\n",
       "19  176.103591\n",
       "20  171.535644\n",
       "21  167.615294\n",
       "22  168.099517\n",
       "23  155.913472\n",
       "24  172.609828\n",
       "25  155.327855\n",
       "26  175.150821\n",
       "27  144.647325\n",
       "28  163.491008\n",
       "29  178.125317\n",
       "30  165.299600\n",
       "31  162.492451\n",
       "32  213.452152\n",
       "33  171.631053\n",
       "34  162.225932\n",
       "35  184.554153\n",
       "36  153.097067\n",
       "37  164.060239\n",
       "38  171.030646\n",
       "39  143.395749\n",
       "40  234.583931\n",
       "41  157.855754\n",
       "42  179.916756\n",
       "43  212.003756\n",
       "44  189.189779\n",
       "45  178.713933\n",
       "46  177.937860\n",
       "47  157.977549\n",
       "48  146.242376\n",
       "49  178.384513\n",
       "50  186.465019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {\n",
    "    'MSE' : []\n",
    "}\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(len(MSE_lst)):\n",
    "    models.append(i+1)\n",
    "    dic['MSE'].append(MSE_lst[i])\n",
    "    \n",
    "report = pd.DataFrame(dic)\n",
    "report.index = models\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deae33e",
   "metadata": {},
   "source": [
    "# Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2b57a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of MSEs: 170.6106516231569\n",
      "Standard Deviation MSEs: 20.651984308130817\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average of MSE         : {np.mean(MSE_lst)}\")\n",
    "print(f\"Standard Deviation MSE : {np.std(MSE_lst)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f39b24",
   "metadata": {},
   "source": [
    "# How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69af01f",
   "metadata": {},
   "source": [
    "The Avg. MSE has reduced from 348.84 to 170.61.\n",
    "The Standard Deviation in the MSE has reduced from 84.45 to 20.65.\n",
    "\n",
    "Which make the model is performance is much better than the model in step B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f6d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
